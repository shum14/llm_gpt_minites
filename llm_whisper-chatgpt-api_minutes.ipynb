{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/ai_voice_writing/blob/main/section_1/01_try_whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DO NOT DISCLOSE YOUR API KEY!!!**"
      ],
      "metadata": {
        "id": "hNctpxFB7pwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAIのAPIキーを取得\n",
        "API_KEY = \"\""
      ],
      "metadata": {
        "id": "8SsO66GBqQIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Google Colab Settings**"
      ],
      "metadata": {
        "id": "p5UKZl0rheap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import os, sys\n",
        "print('Current Directory: ', os.getcwd())\n",
        "\n",
        "ROOT_PATH = '/content/drive/My Drive/Colab Notebooks/'\n",
        "sys.path.append(ROOT_PATH)\n",
        "\n",
        "DATA_PATH = '/content/drive/My Drive/Colab Notebooks/data/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1gxyA3lz6n6",
        "outputId": "08c3e19c-ae07-4be6-8870-dd1459dea5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "Current Directory:  /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQz0MRBkLcDA"
      },
      "source": [
        "# **Import Libraries**\n",
        "\n",
        "- Refrence: OpenAI Documenbt at GitHub\n",
        "    - https://github.com/openai/openai-python/blob/main/api.md\n",
        "    - https://github.com/openai/openai-cookbook/blob/main/examples/Whisper_processing_guide.ipynb\n",
        "    - Api credit is required, but you can try this code for roughly $0.1 or less!\n",
        "\n",
        "- Dataset : 伊賀市議会「令和５年教育民生常任委員会（12月14日）」\n",
        "    - https://www.youtube.com/watch?v=NTy5rGt9Yug\n",
        "    -1. Played the YouTube video and recorded it with voice memo app.\n",
        "    -2. Saved file named 'rec.wav'.\n",
        "    -3. The sample file was tried for 2~3 minutes, but can be made longer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnzcQIXZ8Xt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d20e0e37-94a3-41ce-cff6-fc4f386ecfbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-9gyf45ap\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-9gyf45ap\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802825 sha256=26206e2d7f05f8348e5d01c6c5c267d475510344234142260d879e95c54c7aec\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pnpe005s/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20231117 tiktoken-0.6.0\n",
            "Collecting openai\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.12.0\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install --upgrade openai\n",
        "!pip install pydub\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from openai.types.audio import Transcription\n",
        "import whisper\n",
        "\n",
        "import os\n",
        "import urllib\n",
        "import ssl\n",
        "\n",
        "from IPython.display import Audio\n",
        "from pathlib import Path\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import detect_nonsilent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFmDy-OiM4SC"
      },
      "source": [
        "# **Simple Transcribe with Whisper (without api)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZJDd-mI8lX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e273c8-6991-4ca7-cdba-0b72f3b6e1a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "今後どうしていくかというところに今迫られている状況でその中でも教義を示させていただいておりますただ参考を残すために私たちも参考を残していただきたいというのをお願いをしていますそれは先ほども終わったようにいろんな子どもの受けたらおきちんとして心臓補償していただきたいというのを県にお願いをしてきたと思いますところがその中でやはりご校の側からの意見の中ではこれ以上学校規模が小さくなると魅力化すらできないということの意見が出てきてその中で今後どうしていくかということが今議論されています\n"
          ]
        }
      ],
      "source": [
        "# 音声データの読み込み\n",
        "audio = whisper.load_audio(DATA_PATH + \"rec.wav\") #ファイル名はrec.wav\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "# 音響特徴量（ログメルスペクトグラム）の計算\n",
        "mel = whisper.log_mel_spectrogram(audio).cuda()\n",
        "\n",
        "#言語とモデル規模の設定\n",
        "lang = \"ja\"\n",
        "model = whisper.load_model(\"medium\")\n",
        "\n",
        "# 音声データの文字起こし\n",
        "options = whisper.DecodingOptions(language=lang, without_timestamps=True)\n",
        "result = whisper.decode(model, mel, options)\n",
        "print(result.text)\n",
        "\n",
        "# 結果をファイルに書き込む\n",
        "with open(\"sample_voice.txt\", \"w\") as f:\n",
        "    f.write(result.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General-purpose model with api**"
      ],
      "metadata": {
        "id": "z2iP8ZDDn-fW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 元の音源を分割\n",
        "def split_audio(input_file_path, chunk_length_ms=30000):  # 30秒のセグメントに分割\n",
        "    audio = AudioSegment.from_file(input_file_path, format=\"wav\")\n",
        "    chunks = []\n",
        "\n",
        "    for i in range(0, len(audio), chunk_length_ms):\n",
        "        chunk = audio[i:i+chunk_length_ms]\n",
        "        chunks.append(chunk)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# 無音部分のトリミング\n",
        "def trim_silence(audio_path):\n",
        "    audio = AudioSegment.from_file(audio_path, format=\"wav\")\n",
        "    non_silent_ranges = detect_nonsilent(audio, min_silence_len=100, silence_thresh=-50) #無音と判断する時間と音量の閾値\n",
        "    if non_silent_ranges:\n",
        "        start_trim = non_silent_ranges[0][0] # 開始点：最初の非無音部分のタプル（開始時間, 終了時間）を返す\n",
        "        end_trim = non_silent_ranges[-1][1] # 終了点：最後の非無音部分のタプル（開始時間, 終了時間）を返す\n",
        "        trimmed_audio = audio[start_trim:end_trim]\n",
        "    else:\n",
        "        trimmed_audio = audio\n",
        "\n",
        "    # トリミングしたオーディオを一時ファイルに保存\n",
        "    trimmed_file_path = \"./trimmed.wav\"\n",
        "    trimmed_audio.export(trimmed_file_path, format=\"wav\")\n",
        "    return trimmed_file_path\n",
        "\n",
        "\n",
        "# ビットレートの調整（ファイルサイズの削減）\n",
        "import subprocess\n",
        "def reduce_bitrate(input_file_path, output_file_path, target_bitrate=\"64k\", target_sample_rate=\"22050\"):\n",
        "\n",
        "    #file_size_input = os.path.getsize(input_file_path)\n",
        "    #file_size_output = os.path.getsize(output_file_path)\n",
        "    #print(\"File Size in Bytes:\", file_size_input, file_size_output)\n",
        "\n",
        "    # ffmpegコマンドを使用してビットレートを変更\n",
        "    command = [\n",
        "        \"ffmpeg\",\n",
        "        \"-y\",  # 既存のファイルを上書きすることを許可\n",
        "        \"-i\", input_file_path,  # 入力ファイル\n",
        "        \"-b:a\", target_bitrate,  # オーディオビットレートの設定\n",
        "        \"-ar\", target_sample_rate,  # サンプリングレートの設定\n",
        "        output_file_path  # 出力ファイル\n",
        "    ]\n",
        "    try:\n",
        "        # 標準エラー出力をキャプチャしてエラー発生時に表示\n",
        "        subprocess.run(command, check=True, stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        # エラーメッセージを出力\n",
        "        print(f\"Error occurred: {e.stderr.decode()}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def transcribe_audio(input_file_path):\n",
        "    # 無音部分をトリミングし、その結果のパスを取得\n",
        "    trimmed_file_path = trim_silence(input_file_path) # 原音→トリミング\n",
        "\n",
        "    # ビットレートを下げたファイルを保存するパス\n",
        "    reduced_file_path = \"./reduced.wav\"\n",
        "\n",
        "    # トリミングされ、ビットレートが下げられたファイルを作成\n",
        "    reduce_bitrate(trimmed_file_path, reduced_file_path) # トリミング→圧縮\n",
        "\n",
        "    # 文字起こしを行う\n",
        "    # ファイルをバイナリモードで開き、その内容をAPIに渡す\n",
        "    with open(reduced_file_path, 'rb') as audio_file:  #圧縮 → 音源\n",
        "        transcription_params = {\n",
        "            \"file\": audio_file,\n",
        "            \"model\": \"whisper-1\",\n",
        "            \"language\": \"ja\",\n",
        "        }\n",
        "        # API呼び出しでの正しいメソッド名とパラメータを使用\n",
        "        response = client.audio.transcriptions.create(**transcription_params) # 音源 → 文字起こし\n",
        "        #print(type(response))\n",
        "        #print(dir(response))\n",
        "        transcribed_text = response.text\n",
        "        # レスポンスから文字起こし結果を抽出\n",
        "        #transcribed_text = response[\"choices\"][0][\"text\"]\n",
        "        return transcribed_text\n",
        "\n",
        "\n",
        "def transcribe_chunks(chunks):\n",
        "    transcriptions = []\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "\n",
        "        chunk_file_path = f\"./temp_chunk_{i}.wav\"\n",
        "        chunk.export(chunk_file_path, format=\"wav\") #一時ファイルに保存\n",
        "\n",
        "        transcription = transcribe_audio(chunk_file_path)\n",
        "        transcription_cleaned = transcription.replace(\"\\n\", \" \") #改行を削除\n",
        "        transcriptions.append(transcription_cleaned)\n",
        "        os.remove(chunk_file_path) #使用後の一時ファイルを削除\n",
        "\n",
        "    return transcriptions\n",
        "\n",
        "# APIキーによる認証\n",
        "client = OpenAI(api_key=API_KEY)\n",
        "\n",
        "original_file_path = DATA_PATH + \"rec.wav\"\n",
        "chunks = split_audio(original_file_path)\n",
        "transcriptions = transcribe_chunks(chunks)\n",
        "\n",
        "print(transcriptions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UCROHjDTj-A",
        "outputId": "6db6c4d9-bb56-41f5-fdc3-2f7ee317d9be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['いうことで 今後どうしていくか というところに 今 迫られている 状況で その中でも 協議を示させて いただいております ただ 参考 を残すという 私たちもこれまで 参考 私もですけど 参考を残して いただきたいというのは お願いを してきました それは 先ほども 終わったように いろんなことを 物を受けたらおきちとして 進路 補助をしていただきたいという のを 県にお願いをしてきたと思います ところが その中で やはり 結局 国防側からの意見の中では これ以上 学校規模が小さくなると 魅力化 すらできないということの意見 が出てきて その中で 今後どうして いくかということが 今 議論されて ', '今後も議論をされていくという中で今あるというような状況でございまして 今後子供が減る何年かの段階の中でどうしていくのかを今論議をして その中で決定しているただですね論議はしますけれども最終決定は金教委ですので 論議をしていただいて金教委の中で最終判断をしているというところへ 今来ているというのが現状でございます 実情はよく分かりましたので中学校の進路担当の方も大変悩んでるやろうし 受け入れていく高校の校長先生か教員の方も大変悩ましいことやろうと そういう認識を', '引き続いて、保護者、地域の考え方も伝えていただきながら 進路の確保ということで、教育委員会も取り組んでいただきたいと思います 何かございませんか 今、北山委員からも、イムカセーカ協議会ということの お話の現状のことと、教育庁からも、今議論中であるということも 聞かせていただいたんですけれども', '県立高校のペースのあり方とか そういったものに制限されているわけなんですけども PTAの連合会とか教職組合への対応というのは どういうふうになっているのでしょうか 【佐藤】市教育長 【佐藤】PTA連合会 それから教職組合等ということでございますけれども その以外 地域の高等学校の活性化推進協議会の メンバーの中にですね 小中学校のPTA連合会の方の代表の方 それから高校のPTAの代表の方が出てくれてますし それから教育委員会としては 両教育長が', 'ながらに両教育長が出ておりますし 学校の代表もですね 校長の代表も出ています さらには教職員の代表の方も出ていますので それで高等学校の校長も出ておりますけど そういう中で19名の中でですね 議論をしているということで そこでご意見をいただくというように 今川崎学園協会の中ではなっております 【上杉】ありがとうございます 今その協議会の中の協議の ちょっと資料とかもいただいたんですけども 今この青函であって 秋葉野学園高校の存続ということをするとしたら 他校の影響というのはどのようになるんでしょうか', '県教委の資料によりますとですね 結局ですね この今のまま3校 伊賀地域の5校 残すということでありますとですね 学校規模を自粛するしかない ということになります 私たちはもっとですね 他の学級規模を少なくすることも できるんじゃないかということも 言ってるんですけども 例えば今 伊賀白方向ですとですね 定員40名だったのを35名に一部 していただいているということも ございましてですね そういうこともしながら きみ細かな指導もできるんじゃないか ということで県教委には それは県教委決めることですので 提案もしてお願いをしているところも ございますけども 結局さらに', '子供が減ってくるとなったらそれ だけでも対応できなくなるので 各学校の定員を減らすということ になりますので今後定員を減らす 中で協議をするということになります と各学校ですね今それぞれの学校 から2クラスから3クラス減る必要 がある減らしていく必要がある ということで今の定員の定数から さらに小さくなる学校を作って しまうということでいがち地域 の中ではその小さな学校が本当に 魅力ある学校になるのかどうか ということがそうしたらそんな いがち地域の中から他に出ていく ということになると', '出ていってしまうと思うと、もうなくなりますので、その辺が活性化できるのかどうかということを 今、擬音をしていただいていますし、そこは高校としてはなかなか難しいんじゃないかということも 高校の先生からおご意見をいただいているので、なかなかそこの辺をどういうふうにしていくのかというのが 難しいところだというふうに思っております。 何もございませんか。小野委員。 すみません、スープに質問をさせていただきたいと思います。 先ほど静岡県の方から、ボーダーラインの子どもたちもいるいて、社会に出て 自分のおじいちゃんになるのが強みであると、 小野高校の方にも議会を聞いてきているというふうに申し上げていただいたんですけれども、', '実際、私の教えている方で、何年か野球場の高校に在住していて、手帳を持っていらっしゃる子どもさんがいらっしゃるんです。 現実的に、車の免許がまず取れない、また就職が決まらないという形で、悩んでいらっしゃる方もいるというのを、ちょっとご理解いただけたらなと思います。 質問させていただくんですけれども、青岩のところに地域活性化への貢献の一つになろうというふうに記載していただいてあるんですけれども、 今までどのように地域活性化に貢献されてこれたか、こんなところのところがね。', 'その経緯を各5年ぐらいで言うので 静岡市の方にお聞きしたいと思います 【佐藤】藍澤さん 【藍澤】ご質問ありがとうございます まず一つ前提的なことを言わせてもらうと 地域に学校があるとないことでは 地域の活力が全然違うんじゃないかなと 思うんです これまでいらっしゃる小学校の中学校の同盟があって いくつかの学校が地域から消えていったんですけども 私も現職の時は教職に行ってましたので そういうことが実感してよくわかります そういうことは私の個人的な感覚だけじゃなく', '多分、地域の方々も同じようなそういう感覚を持っていらっしゃるんじゃないかと。 それは、一般論としてそういうことが言えるんじゃないかと思うんです。 で、あくまでも広報につきましてはですね、 例えば、地域の活性化ということで、 あのー、 【質問者】国境の決断の予定ですか? 【加藤】本当に、広木神社っていうお店なんですよね。 そこに、新聞報道にもあったんですけども、 エマを奉納するというね、そういう活動を地域に奉迎しています。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summerize with ChatGPT**"
      ],
      "metadata": {
        "id": "CfRAFVFGrbPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_text(text, system_message, prompt):\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_message}, #role:役割とcontent:条件の指定\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.1,  # クリエイティブさの度合いを調整\n",
        "        max_tokens=1000  # 生成するトークンの最大数を指定（プロンプトでコントロール / 文字数ではない）\n",
        "    )\n",
        "\n",
        "    # APIレスポンスから要約されたテキストを得る\n",
        "    # そのうち最初の選択肢(choice[0])のレスポンス(message)と要約文章(content)を取得する\n",
        "    summarized_text = completion.choices[0].message.content\n",
        "    return summarized_text\n",
        "\n",
        "\n",
        "# GPTに要約を依頼する際の要件とプロンプト文を設定\n",
        "system_message = '''\n",
        "以下の要件に基づき、文章を整理し議事録としてまとめてください。\n",
        "\n",
        "【要件】\n",
        "* 現状を把握し、話の全体像がわかるように250文字以内で要約してください。\n",
        "*　個人の主張を50文字以内で5つまで記述してください。その時名前を含めてください。\n",
        "* 今後取るべき具体的なアクションを100文字以内で記述してください。\n",
        "* 議題を1つ100文字以内で記述してください。\n",
        "* 採決が行われた場合、その内容と結果（賛成票と反対票の数）を記述してください。\n",
        "* 議事録以外の文章は記述しないでください。\n",
        "'''\n",
        "\n",
        "prompt = f\"以下のテキストを要約してください:\\n\\n{transcriptions}\"\n",
        "\n",
        "# transcribe_audioで得られたテキストを要約\n",
        "summarized_text = summarize_text(transcriptions, system_message, prompt)\n",
        "print(summarized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLIsozZ973Mc",
        "outputId": "e80f3ee0-f5f6-4f95-ec6e-adec4ab8f149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "要約：\n",
            "現在、学校の規模や進路に関する協議が行われており、子供の減少による影響や地域の活性化について検討されている。教育委員会や地域の関係者が参加し、最終決定は教育委員会が行う。各学校の定員削減や地域貢献についても話し合われている。\n",
            "\n",
            "個人の主張：\n",
            "1. 【佐藤】: \"学校の規模を小さくすることも検討すべき。\"\n",
            "2. 【上杉】: \"他校の存続がどのように影響するか考慮すべき。\"\n",
            "3. 【小野】: \"地域活性化への貢献を重視し、学校の存在価値を考えるべき。\"\n",
            "4. 【藍澤】: \"学校の存在が地域の活力につながると考える。\"\n",
            "5. 【加藤】: \"地域貢献活動を通じて地域の活性化に貢献している。\"\n",
            "\n",
            "アクション：\n",
            "学校の定員削減や地域貢献活動を進め、教育委員会と地域の連携を強化して、地域の活性化と学校の存続を促進する。\n",
            "\n",
            "議題：\n",
            "学校の規模や進路に関する協議と地域活性化についての検討。\n",
            "\n",
            "採決：\n",
            "採決は行われていない。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KgL1eDWDFzLK"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}